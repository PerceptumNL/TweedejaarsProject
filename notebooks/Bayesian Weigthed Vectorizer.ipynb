{
 "metadata": {
  "name": "",
  "signature": "sha256:70d0b27ab693c354424cf3025b2412bca876191dfeeab27675b9be8dfbb735e9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bayesian Weighted Vectorizer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are interested in $P(d_i \\to d_j \\mid T(d_i)\\cap T(d_j))$ where $d_i \\to d_j$ means that document $d_i$ is linked to (directed) $d_j$. In other words: the probability that document $d_i$ and $d_j$ should have a (directed) link between them given the tags that they are both associated with.\n",
      "\n",
      "\\begin{align}\n",
      "    T &= \\text{the set of all tags.} \\\\\n",
      "    D &= \\text{Is the set of all documents: $\\{d_1, d_2, \\ldots, d_n\\}$.} \\\\\n",
      "    L &= \\text{The set of all links: $\\{d_i \\to d_j\\mid d_{\\{i,j\\}} \\in D\\}$ where $d_{\\{i,j\\}}$ are linked.} \\\\\n",
      "    D_t &= \\text{The set of documents associated with tag $t$: } \\{d_i \\mid d_i \\in D \\land t \\in T(d_i)\\} \\\\\n",
      "    T(d_i) &= \\text{The set of all tags associated with document $d_i$.} \\\\\n",
      "    P(d_i \\to d_j) &= \\text{The probability that two documents $d_{\\{i,j\\}}$ with a specific type are linked.} \\\\\n",
      "    P(t) &= \\text{The probability that the tag $t$ appears in two documents} \\\\\n",
      "    P(t\\mid d_i \\to d_j) &= \\text{The probability that document $d_{\\{i,j\\}}$ are associated with tag $t$ given that they are linked.}\n",
      "\\end{align}\n",
      "\n",
      "Ideally we would compute the probability given the set of intersection of both tags sets. However to compute this we need to compute this for the powerset of $T$. For a set of just $100$ tags this would results in $2^{100}$ of sets for which a probability needs to be estimated. This is untractable. So instead we compute \n",
      "\n",
      "$$\\max\\limits_{t \\in T(d_i)\\cap T(d_j)} P(d_i \\to d_j\\mid t)$$\n",
      "\n",
      "Above all the parts we need to compute $P(d_i \\to d_j \\mid t)$ are given. We will now specify these more exact and explain how these probabilities will we used to compute a document similarity metric. Using bayes rule we can rewrite this to:\n",
      "\n",
      "$$P(d_i \\to d_j \\mid t) = \\frac{P(t\\mid d_i \\to d_j)P(d_i \\to d_j)}{P(t)}$$\n",
      "\n",
      "These seperate probabilities we can compute seperately. First $P(t)$ is the probability that two seperately selected documents where order doesn't matter have the same tags. Computationally this comes down to:\n",
      "\n",
      "$$P(t) = \\frac{|D_t| \\choose 2}{|D| \\choose 2} = \\frac{|D_t|\\cdot(|D_t| - 1)}{|D| \\cdot (|D| - 1)}\n",
      "\\stackrel{\\text{laplace}}{\\Longrightarrow} \\frac{|D_t|\\cdot(|D_t| - 1) + k}{|D| \\cdot (|D| - 1) + k|D|} $$\n",
      "\n",
      "Next we define $P(t|d_i \\to d_j)$.\n",
      "\n",
      "$$P(t|d_i \\to d_j) = \\frac{|\\{l = d_i \\to d_j \\mid l \\in L \\land t \\in T(d_i) \\cap T(d_j)\\}|}{|L|}$$\n",
      "\n",
      "Last we need to compute $P(d_i \\to d_j)$. This is the probability that a document with type of $d_I$ ($\\text{type}(d_i)$) is linked to a document of $\\text{type}(d_j)$. This will result in a matrix of probabilities where for each type combination (order does matter) a probability is computed. Below we compute these for the data export of june 12th. For some types there are no links to some other types. We do not want to assign a probability of zero so we use laplace smoothing to assign the probabilities. The table below displays the type-link probability of two document. The probabilities are displayed from a document of a type in the left most row to a document in a column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys\n",
      "sys.path.append(os.path.join(os.path.abspath('..'), 'src'))\n",
      "from datawrapper import DataWrapper\n",
      "from collections import Counter\n",
      "import pandas\n",
      "import numpy as np\n",
      "\n",
      "data = DataWrapper('../data/export_starfish_tjp_12jun.pickle')\n",
      "items = lambda: ((item, data.item(item)) for item in data.items()) # Generator for all items\n",
      "stype = lambda item: data.item(item)['type']\n",
      "\n",
      "types = {item[1]['type'] for item in items()} # get all unique types\n",
      "\n",
      "out_links = {t:Counter() for t in types}\n",
      "for item, item_dict in items(): \n",
      "    out_links[stype(item)].update([stype(i) for i in item_dict['links']])\n",
      "    \n",
      "def laplace(total, types, from_t, to_t, k):\n",
      "    smoothed_count = total[from_t].get(to_t, 0) + k\n",
      "    total_count = sum(total[from_t].values())\n",
      "    smoothed_total = total_count + len(types)*k\n",
      "    return smoothed_count/float(smoothed_total)\n",
      "\n",
      "prob = {from_t:[laplace(out_links, types, from_t, to_t, 1) for to_t in types] for from_t in types}\n",
      "pandas.DataFrame({k:pandas.Series(v, index=types) for k,v in prob.items()}, \n",
      "                 columns=types).transpose()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Information</th>\n",
        "      <th>Glossary</th>\n",
        "      <th>Question</th>\n",
        "      <th>Good Practice</th>\n",
        "      <th>Project</th>\n",
        "      <th>Person</th>\n",
        "      <th>Event</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Information</th>\n",
        "      <td> 0.267045</td>\n",
        "      <td> 0.272727</td>\n",
        "      <td> 0.073864</td>\n",
        "      <td> 0.034091</td>\n",
        "      <td> 0.051136</td>\n",
        "      <td> 0.278409</td>\n",
        "      <td> 0.022727</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Glossary</th>\n",
        "      <td> 0.357466</td>\n",
        "      <td> 0.199095</td>\n",
        "      <td> 0.031674</td>\n",
        "      <td> 0.045249</td>\n",
        "      <td> 0.081448</td>\n",
        "      <td> 0.266968</td>\n",
        "      <td> 0.018100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Question</th>\n",
        "      <td> 0.265306</td>\n",
        "      <td> 0.224490</td>\n",
        "      <td> 0.020408</td>\n",
        "      <td> 0.081633</td>\n",
        "      <td> 0.081633</td>\n",
        "      <td> 0.306122</td>\n",
        "      <td> 0.020408</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Good Practice</th>\n",
        "      <td> 0.176471</td>\n",
        "      <td> 0.205882</td>\n",
        "      <td> 0.117647</td>\n",
        "      <td> 0.088235</td>\n",
        "      <td> 0.058824</td>\n",
        "      <td> 0.235294</td>\n",
        "      <td> 0.117647</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Project</th>\n",
        "      <td> 0.196078</td>\n",
        "      <td> 0.274510</td>\n",
        "      <td> 0.078431</td>\n",
        "      <td> 0.039216</td>\n",
        "      <td> 0.098039</td>\n",
        "      <td> 0.274510</td>\n",
        "      <td> 0.039216</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Person</th>\n",
        "      <td> 0.410112</td>\n",
        "      <td> 0.348315</td>\n",
        "      <td> 0.067416</td>\n",
        "      <td> 0.044944</td>\n",
        "      <td> 0.078652</td>\n",
        "      <td> 0.005618</td>\n",
        "      <td> 0.044944</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Event</th>\n",
        "      <td> 0.160000</td>\n",
        "      <td> 0.160000</td>\n",
        "      <td> 0.040000</td>\n",
        "      <td> 0.160000</td>\n",
        "      <td> 0.080000</td>\n",
        "      <td> 0.320000</td>\n",
        "      <td> 0.080000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "               Information  Glossary  Question  Good Practice   Project  \\\n",
        "Information       0.267045  0.272727  0.073864       0.034091  0.051136   \n",
        "Glossary          0.357466  0.199095  0.031674       0.045249  0.081448   \n",
        "Question          0.265306  0.224490  0.020408       0.081633  0.081633   \n",
        "Good Practice     0.176471  0.205882  0.117647       0.088235  0.058824   \n",
        "Project           0.196078  0.274510  0.078431       0.039216  0.098039   \n",
        "Person            0.410112  0.348315  0.067416       0.044944  0.078652   \n",
        "Event             0.160000  0.160000  0.040000       0.160000  0.080000   \n",
        "\n",
        "                 Person     Event  \n",
        "Information    0.278409  0.022727  \n",
        "Glossary       0.266968  0.018100  \n",
        "Question       0.306122  0.020408  \n",
        "Good Practice  0.235294  0.117647  \n",
        "Project        0.274510  0.039216  \n",
        "Person         0.005618  0.044944  \n",
        "Event          0.320000  0.080000  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the table above we can see that for example a document with type 'Information' has a $0.267045$ probability of being linked with another document of type 'Information' and a $0.034091$ probability of being linked with a document of type 'Good Practice'"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This approach still has"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "\n",
      "\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 22pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<IPython.core.display.HTML at 0x7f5cb04d4510>"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}