{
 "metadata": {
  "name": "",
  "signature": "sha256:3299a6d995b4e079e10cca2d465ca120eceeb609f3ec409cefee9f0345e8e209"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# add this to top of document such that import from src folder work.\n",
      "import os, sys\n",
      "sys.path.append(os.path.join(os.path.abspath('..'), 'src')) \n",
      "\n",
      "# the following line configures ipython to show matplotlib inline\n",
      "%matplotlib inline\n",
      "\n",
      "# enable d3 for matplotlib\n",
      "import mpld3\n",
      "mpld3.enable_notebook()\n",
      "\n",
      "# Do matplotlib import such that these are available throughout notebook\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Distance Threshold"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The nearest neighbor algorithm will return a list of ordered documents and their distance to the new document in the chosen space. Currently we accept the first 10 (or any other arbitrary number) as the threshold for which document to include as proposed linked document and which not. However, our intuition says that this is suboptimal as some document should only have two proposed documents and other should have 12. In this notebook we will analyse different options to use a more variable (e.g. based on the results) threshold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import datawrapper\n",
      "import DocumentLinker\n",
      "import numpy as np\n",
      "import cPickle as pickle\n",
      "from vectorizers import weighted_tagvectorizer\n",
      "\n",
      "# get a datawrapper\n",
      "data = datawrapper.DataWrapper('../data/expert_maybe_false.pickle')\n",
      "link_frequencies = map(lambda x: len(x[0]['links']) , data.test_data())\n",
      "\n",
      "methods = ['weighted_tagvectorizer', 'textvectorizer', 'tag_smoothing', 'glossaries_of_tags']\n",
      "\n",
      "for method in methods:\n",
      "    try:\n",
      "        pickle_dict = open('../data/thres_' + method + '.pickle')\n",
      "        links = pickle.load(pickle_dict)\n",
      "    except IOError as e:\n",
      "        links = []\n",
      "        # create a 'test document' and 'test dataset'\n",
      "        for test_doc, test_data in data.test_data():\n",
      "            linker = DocumentLinker.DocumentLinker(test_data, k=1000)\n",
      "            links += [(len(test_doc['links']), linker.get_links(test_doc, vtype=method, dtype='cosine'))]\n",
      "        pickle.dump(links, open( '../data/thres_' + method + '.pickle', \"wb\" ))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from scipy import stats\n",
      "\n",
      "print(\"Link statistics over {0} documents\".format(len(link_frequencies)))\n",
      "print(\"Avarage  : {0}\".format(np.average(link_frequencies)))\n",
      "print(\"Variance : {0}\".format(np.var(link_frequencies)))\n",
      "print(\"Min      : {0}\".format(np.min(link_frequencies)))\n",
      "print(\"Max      : {0}\".format(np.max(link_frequencies)))\n",
      "print(\"Median   : {0}\".format(np.median(link_frequencies)))\n",
      "\n",
      "plt.hist(link_frequencies, max(link_frequencies))\n",
      "plt.xlabel(\"Number of links in document\")\n",
      "plt.ylabel(\"Frequency\")\n",
      "plt.title(\"Frequencies for number of links in document\")\n",
      "link_frequencies_no_zero = [x for x in link_frequencies if (x != 0 and x < 30)]\n",
      "\n",
      "print(\"\\nLink statistics (documents with 0 links and natasa removed):\")\n",
      "print(\"Avarage  : {0}\".format(np.average(link_frequencies_no_zero)))\n",
      "print(\"Variance : {0}\".format(np.var(link_frequencies_no_zero)))\n",
      "print(\"Min      : {0}\".format(np.min(link_frequencies_no_zero)))\n",
      "print(\"Max      : {0}\".format(np.max(link_frequencies_no_zero)))\n",
      "print(\"Median   : {0}\".format(np.median(link_frequencies_no_zero)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.cm import ScalarMappable\n",
      "from matplotlib.colors import Normalize \n",
      "from numpy.matlib import repmat\n",
      "\n",
      "colors = ScalarMappable(Normalize(0,10), 'cool')\n",
      "\n",
      "for method in methods:\n",
      "    pickle_dict = open('../data/thres_' + method + '.pickle')\n",
      "    links = pickle.load(pickle_dict)\n",
      "    for link in links:\n",
      "        plt.plot(map(lambda x: 1-np.abs(x[1]), link[1]), '-', color=colors.to_rgba(link[0]))\n",
      "    plt.title(method)\n",
      "    plt.axis([0,120, 0, 1.1])\n",
      "    plt.show()\n",
      "    \n",
      "    differences = np.zeros([len(links), len(links[0][1])-1])\n",
      "    for i, link in enumerate(links):\n",
      "        numbers = map(lambda x: 1-np.abs(x[1]), link[1])\n",
      "        differences[i,:] = map(lambda x: x[1]-x[0], zip(numbers, numbers[1:]))\n",
      "        plt.plot(differences[i,:], color=colors.to_rgba(link[0]))\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_at_threshold(li, threshold):\n",
      "    closest_distance = next((x for x in li if x > 0), None)\n",
      "    l1 = []\n",
      "    l2 = []\n",
      "    for i, x in enumerate(li):\n",
      "        max_diff = ((len(li) - i)/float(len(li)) * threshold * (1 - closest_distance))\n",
      "\n",
      "        try:\n",
      "            x = x[0,0]\n",
      "        except Exception, c:\n",
      "            x = x\n",
      "        if x <= closest_distance + max_diff and x < 1.0:\n",
      "            l1.append(x)\n",
      "        else:\n",
      "            l2.append(x)\n",
      "    return (l1, l2)\n",
      "\n",
      "found = []\n",
      "for link in links:\n",
      "    if link[0] > 2:\n",
      "        li = map(lambda x: 1-np.abs(x[1]), link[1])\n",
      "        (l1, l2) = split_at_threshold(li, 0.2)\n",
      "        print(\"Found: {0} \\t needed: {1}\".format(len(l1), link[0]))\n",
      "        found.append(len(l1))\n",
      "        plt.plot(range(1, len(l1)+1), l1, '-b')\n",
      "        plt.plot(range(len(l1), len(l1)+len(l2)), l2, '-.r')\n",
      "        plt.plot((link[0], link[0]), (0, 1.1))\n",
      "        plt.axis([0,100, 0, 1.1])\n",
      "        plt.show()\n",
      "print(found)\n",
      "print(\"Avarage  : {0}\".format(np.average(found)))\n",
      "print(\"Variance : {0}\".format(np.std(found)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Gaussian processes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.gaussian_process import GaussianProcess \n",
      "\n",
      "# gp = GaussianProcess(storage_mode = 'light', verbose=True)\n",
      "\n",
      "# X = np.reshape(differences, [differences.size, 1])\n",
      "# y = np.matrix(range(0, differences.shape[1])).T\n",
      "# y = repmat(y, differences.shape[0], 1)\n",
      "# print(X.shape)\n",
      "# print(y)\n",
      "# print(y.shape)\n",
      "# # gp.fit(np.matrix([1, 2]).T, np.matrix([1, 1]).T)\n",
      "\n",
      "# # # Make the prediction on the meshed x-axis (ask for MSE as well)\n",
      "# # y_pred, MSE = gp.predict(x, eval_MSE=True)\n",
      "# # sigma = np.sqrt(MSE)\n",
      "\n",
      "# # plt.plot(np.mean(differences,0), 'r')\n",
      "# # plt.title(method + \" differences\")\n",
      "# # plt.show()\n",
      "# # # Plot the function, the prediction and the 95% confidence interval based on\n",
      "# # # the MSE\n",
      "# # fig = plt.figure()\n",
      "# # plt.plot(x, f(x), 'r:', label=u'$f(x) = x\\,\\sin(x)$')\n",
      "# # plt.plot(X, y, 'r.', markersize=10, label=u'Observations')\n",
      "# # plt.plot(x, y_pred, 'b-', label=u'Prediction')\n",
      "# # plt.fill(np.concatenate([x, x[::-1]]),\n",
      "# #         np.concatenate([y_pred - 1.9600 * sigma,\n",
      "# #                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
      "# #         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
      "# # plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}