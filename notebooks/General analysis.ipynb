{
 "metadata": {
  "name": "",
  "signature": "sha256:394b226b277ea0c12733fd84b9517fe63d7ee66c41c2efcba8aa221fbe8a546b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys\n",
      "from decimal import Decimal\n",
      "sys.path.append(os.path.join(os.path.abspath('..'), 'src'))\n",
      "from DocumentLinker import DocumentLinker\n",
      "from datawrapper import DataWrapper\n",
      "import json\n",
      "\n",
      "# Determine name of author (for visualization)\n",
      "def __find_author_name(linker, author_id):\n",
      "    if(author_id == linker.document['id']):\n",
      "        author = linker.document['name']\n",
      "    else:\n",
      "        try:\n",
      "            author = linker.data.item(author_id)['name']\n",
      "        except KeyError:\n",
      "            author = 'unknown'\n",
      "    return author\n",
      "\n",
      "# Check if a link should be added or ignored\n",
      "def ignore(new_doc, link, data): \n",
      "    # Ignore if proposed link simply is the author of the doucment \\\n",
      "    if (new_doc.has_key('author') and new_doc['author'] == link):\n",
      "        return True\n",
      "    \n",
      "    # Ignore if link is glossary \n",
      "    if (data.item(link)['type'] == 'Glossary'):\n",
      "        return True\n",
      "    \n",
      "    # Ignore if proposed link is simply a document written by person described by document \\\n",
      "    if (new_doc['type'] == 'Person' and data.item(link).has_key('author') and data.item(link)['author'] == new_doc['id']):\n",
      "        return True\n",
      "    return False\n",
      "    \n",
      "# Same as in DocumentLinker.py, only now not k = 10 but k = known amount of links in doc   \n",
      "def run(vectorizer, distancetype):\n",
      "    data = DataWrapper('../data/expert_maybe_true.pickle')\n",
      "    data.remove_aliased_tags()\n",
      "    filename = \"../data/final_analysis/{0}_{1}.json\".format(vectorizer, distancetype)\n",
      "\n",
      "    c = 0\n",
      "    docs = {}\n",
      "    percentage = 0\n",
      "    \n",
      "    # Return ranking of all documents\n",
      "    k = len(data.data['items']) - 1\n",
      "    \n",
      "    for new_doc, datawrapper in data.test_data():\n",
      "        linker = DocumentLinker(datawrapper, k)\n",
      "        linker.get_links(new_doc, vtype=vectorizer, dtype=distancetype)\n",
      "        \n",
      "        # Remove all invalid ones from new doc\n",
      "        for link in new_doc['links']:\n",
      "            if (ignore(new_doc, link, data)):\n",
      "                index = new_doc['links'].index(link)\n",
      "                del new_doc['links'][index]\n",
      "        \n",
      "        l = len(new_doc['links'])\n",
      "        if(l == 0):\n",
      "            print('No valid links for {0}'.format(new_doc['id']))\n",
      "            continue\n",
      "        \n",
      "        # Remove all invalid ones from proposed and take number equal to new_doc\n",
      "        i = 0\n",
      "        for link in linker.links:\n",
      "            if(i == l):\n",
      "                break\n",
      "            if (ignore(new_doc, link[0], data)):\n",
      "                index = linker.links.index(link)\n",
      "                del linker.links[index]\n",
      "            else:\n",
      "                i += 1\n",
      "        linker.links = linker.links[0:l]        \n",
      "        links = linker.formatted_links()\n",
      "        \n",
      "        # The following is similar as in DocumentLinker.py \n",
      "        docs[c] = links\n",
      "        c += 1\n",
      "        correct = 0\n",
      "        for link in linker.links:\n",
      "            if(link[0] in new_doc['links']):\n",
      "                correct += 1\n",
      "        if(len(new_doc['links']) > 0):\n",
      "            percentage_correct = Decimal(correct)/len(new_doc['links'])\n",
      "        else:\n",
      "            percentage_correct = 0\n",
      "            print('No links')\n",
      "            c -= 1\n",
      "        percentage += percentage_correct\n",
      "        print('{0} Percentage correct: {1}'.format(new_doc['id'], percentage_correct))\n",
      "\n",
      "    print('Average percentage correct: {0}'.format(Decimal(percentage)/c))\n",
      "    file = open(filename, \"w\")\n",
      "    file.write(json.dumps(docs))\n",
      "    file.close()\n",
      "    \n",
      "import json\n",
      "from decimal import *\n",
      "import numpy as np\n",
      "\n",
      "# Determines percentage correct per type \n",
      "def percentage_correct_per_type(vectorizer, distance):\n",
      "    json_data= open('../data/final_analysis/{0}_{1}.json'.format(vectorizer, distance)).read()\n",
      "    data = json.loads(json_data)\n",
      "\n",
      "    percentages = {}\n",
      "\n",
      "    for doc in data:\n",
      "        correct = 0\n",
      "        total = 0\n",
      "        for link in data[doc]['links']:\n",
      "            rlink = data[doc]['links'][link]\n",
      "            if rlink.has_key('correct') and rlink['correct'] == True:\n",
      "                correct += 1\n",
      "                total += 1\n",
      "            if rlink.has_key('not_recalled') and rlink['not_recalled'] == True:\n",
      "                total += 1\n",
      "\n",
      "        percentage = Decimal(correct)/total\n",
      "        ntype = data[doc]['type']\n",
      "        if percentages.has_key(ntype):\n",
      "            percentages[ntype].append(percentage)\n",
      "        else:\n",
      "            percentages[ntype] = [percentage]\n",
      "\n",
      "    for ntype in percentages:\n",
      "        mean = np.mean(percentages[ntype])\n",
      "        if len(ntype) < 8:\n",
      "            ntype += '\\t'\n",
      "        print('{0} \\t{1}'.format(ntype, mean))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run('tag_smoothing', 'cosine')\n",
      "percentage_correct_per_type('tag_smoothing', 'cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 Percentage correct: 0.3\n",
        "Tag MapleTA not previously seen, ignoring..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2 Percentage correct: 0.6666666666666666666666666667\n",
        "3 Percentage correct: 0.625"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5 Percentage correct: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 Percentage correct: 0.8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8 Percentage correct: 0.6666666666666666666666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9 Percentage correct: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "No valid links for 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Tag LearningAnalyticsDashboard not previously seen, ignoring..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Tag LearningRecordStore not previously seen, ignoring...\n",
        "11 Percentage correct: 0.4285714285714285714285714286"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12 Percentage correct: 0.7777777777777777777777777778"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "No valid links for 14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20 Percentage correct: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21 Percentage correct: 0.1666666666666666666666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22 Percentage correct: 0.6666666666666666666666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23 Percentage correct: 0.5714285714285714285714285714"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24 Percentage correct: 0.5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26 Percentage correct: 0.4285714285714285714285714286"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Tag GoogleDocs not previously seen, ignoring..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "No valid links for 27\n",
        "28 Percentage correct: 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29 Percentage correct: 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "31 Percentage correct: 0.6666666666666666666666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32 Percentage correct: 0.3333333333333333333333333333"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "No valid links for 34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "No valid links for 36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38 Percentage correct: 0.5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39 Percentage correct: 0.2"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run('textvectorizer', 'cosine')\n",
      "percentage_correct_per_type('textvectorizer', 'cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run('weighted_text_vectorizer', 'cosine')\n",
      "percentage_correct_per_type('weighted_text_vectorizer', 'cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run('glossaries_of_tags', 'cosine')\n",
      "percentage_correct_per_type('glossaries_of_tags', 'cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run('simple_tag_similarity', 'cosine')\n",
      "percentage_correct_per_type('simple_tag_similarity', 'cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}