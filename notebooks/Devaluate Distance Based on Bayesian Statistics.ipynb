{
 "metadata": {
  "name": "",
  "signature": "sha256:9355fc8485e222869b6abffe812bd76eefecc99745f287759c6ff166cdc379ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys\n",
      "sys.path.append(os.path.join(os.path.abspath('..'), 'src'))  \n",
      "\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devaluate Distance Based on Bayesian Statistics\n",
      "---------------------------\n",
      "***\n",
      "\n",
      "We are interested in $P(d_i \\to d_j \\mid T(d_i)\\cap T(d_j))$ where $d_i \\to d_j$ means that document $d_i$ is linked to (directed) $d_j$. In other words: the probability that document $d_i$ and $d_j$ should have a (directed) link between them given the tags that they are both associated with.\n",
      "\n",
      "\\begin{align}\n",
      "    T &= \\text{the set of all tags.} \\\\\n",
      "    D &= \\text{Is the set of all documents: $\\{d_1, d_2, \\ldots, d_n\\}$.} \\\\\n",
      "    L &= \\text{The set of all links: $\\{d_i \\to d_j\\mid d_{\\{i,j\\}} \\in D\\}$ where $d_{\\{i,j\\}}$ are linked.} \\\\\n",
      "    D_t &= \\text{The set of documents associated with tag $t$: } \\{d_i \\mid d_i \\in D \\land t \\in T(d_i)\\} \\\\\n",
      "    T(d_i) &= \\text{The set of all tags associated with document $d_i$.} \\\\\n",
      "    P(d_i \\to d_j) &= \\text{The probability that two documents $d_{\\{i,j\\}}$ with a specific type are linked.} \\\\\n",
      "    P(t) &= \\text{The probability that the tag $t$ appears in two documents} \\\\\n",
      "    P(t\\mid d_i \\to d_j) &= \\text{The probability that document $d_{\\{i,j\\}}$ are associated with tag $t$ given that they are linked.}\n",
      "\\end{align}\n",
      "\n",
      "Ideally we would compute the probability given the set of intersection of both tags sets. However to compute this we need to compute this for the powerset of $T$. For a set of just $100$ tags this would results in $2^{100}$ of sets for which a probability needs to be estimated. This is untractable. So instead we compute \n",
      "\n",
      "$$\\max\\limits_{t \\in T(d_i)\\cap T(d_j)} P(d_i \\to d_j\\mid t)$$\n",
      "\n",
      "Above all the parts we need to compute $P(d_i \\to d_j \\mid t)$ are given. We will now specify these more exact and explain how these probabilities will we used to compute a document similarity metric. Using bayes rule we can rewrite this to:\n",
      "\n",
      "$$P(d_i \\to d_j \\mid t) = \\frac{P(t\\mid d_i \\to d_j)P(d_i \\to d_j)}{P(t)}$$\n",
      "\n",
      "These seperate probabilities we can compute seperately. First $P(t)$ is the probability that two seperately selected documents where order doesn't matter have the same tags. Computationally this comes down to:\n",
      "\n",
      "$$P(t) = \\frac{|D_t| \\choose 2}{|D| \\choose 2} = \\frac{|D_t|\\cdot(|D_t| - 1)}{|D| \\cdot (|D| - 1)}\n",
      "\\stackrel{\\text{laplace}}{\\Longrightarrow} \\frac{|D_t|\\cdot(|D_t| - 1) + k}{|D| \\cdot (|D| - 1) + k|D|} $$\n",
      "\n",
      "Next we define $P(t|d_i \\to d_j)$.\n",
      "\n",
      "$$P(t|d_i \\to d_j) = \\frac{|\\{l = d_i \\to d_j \\mid l \\in L \\land t \\in T(d_i) \\cap T(d_j)\\}|}{|L|}$$\n",
      "\n",
      "Last we need to compute $P(d_i \\to d_j)$. This is the probability that a document with type of $d_I$ ($\\text{type}(d_i)$) is linked to a document of $\\text{type}(d_j)$. This will result in a matrix of probabilities where for each type combination (order does matter) a probability is computed. Below we compute these for the data export of june 12th. For some types there are no links to some other types. We do not want to assign a probability of zero so we use laplace smoothing to assign the probabilities. The table below displays the type-link probability of two document. The probabilities are displayed from a document of a type in the left most row to a document in a column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datawrapper import DataWrapper\n",
      "import prob\n",
      "import pandas\n",
      "import numpy as np\n",
      "\n",
      "data = DataWrapper('../data/expert_maybe_true.pickle')\n",
      "data.remove_aliased_tags()\n",
      "items = lambda: ((item, data.item(item)) for item in data.items()) # Generator for all items\n",
      "types = {item[1]['type'] for item in items()} # get all unique types\n",
      "\n",
      "probs = {k:v.values() for k,v in prob.compute_link_probs(data, 1).items()}\n",
      "pandas.DataFrame({k:pandas.Series(v, index=types) for k,v in probs.items()}, \n",
      "                 columns=types).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/jornpeters/Dropbox/Personal/School/TweedejaarsProject/pyenv/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Information</th>\n",
        "      <th>Glossary</th>\n",
        "      <th>Question</th>\n",
        "      <th>Good Practice</th>\n",
        "      <th>Project</th>\n",
        "      <th>Person</th>\n",
        "      <th>Event</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Information</th>\n",
        "      <td> 0.069544</td>\n",
        "      <td> 0.057554</td>\n",
        "      <td> 0.015588</td>\n",
        "      <td> 0.008393</td>\n",
        "      <td> 0.010791</td>\n",
        "      <td> 0.065947</td>\n",
        "      <td> 0.008393</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Glossary</th>\n",
        "      <td> 0.094724</td>\n",
        "      <td> 0.052758</td>\n",
        "      <td> 0.008393</td>\n",
        "      <td> 0.011990</td>\n",
        "      <td> 0.021583</td>\n",
        "      <td> 0.070743</td>\n",
        "      <td> 0.004796</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Question</th>\n",
        "      <td> 0.017986</td>\n",
        "      <td> 0.013189</td>\n",
        "      <td> 0.022782</td>\n",
        "      <td> 0.011990</td>\n",
        "      <td> 0.011990</td>\n",
        "      <td> 0.021583</td>\n",
        "      <td> 0.005995</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Good Practice</th>\n",
        "      <td> 0.009592</td>\n",
        "      <td> 0.008393</td>\n",
        "      <td> 0.007194</td>\n",
        "      <td> 0.003597</td>\n",
        "      <td> 0.004796</td>\n",
        "      <td> 0.009592</td>\n",
        "      <td> 0.005995</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Project</th>\n",
        "      <td> 0.014388</td>\n",
        "      <td> 0.016787</td>\n",
        "      <td> 0.007194</td>\n",
        "      <td> 0.003597</td>\n",
        "      <td> 0.011990</td>\n",
        "      <td> 0.017986</td>\n",
        "      <td> 0.007194</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Person</th>\n",
        "      <td> 0.092326</td>\n",
        "      <td> 0.074341</td>\n",
        "      <td> 0.017986</td>\n",
        "      <td> 0.009592</td>\n",
        "      <td> 0.019185</td>\n",
        "      <td> 0.002398</td>\n",
        "      <td> 0.011990</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Event</th>\n",
        "      <td> 0.008393</td>\n",
        "      <td> 0.004796</td>\n",
        "      <td> 0.001199</td>\n",
        "      <td> 0.004796</td>\n",
        "      <td> 0.003597</td>\n",
        "      <td> 0.009592</td>\n",
        "      <td> 0.004796</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "               Information  Glossary  Question  Good Practice   Project  \\\n",
        "Information       0.069544  0.057554  0.015588       0.008393  0.010791   \n",
        "Glossary          0.094724  0.052758  0.008393       0.011990  0.021583   \n",
        "Question          0.017986  0.013189  0.022782       0.011990  0.011990   \n",
        "Good Practice     0.009592  0.008393  0.007194       0.003597  0.004796   \n",
        "Project           0.014388  0.016787  0.007194       0.003597  0.011990   \n",
        "Person            0.092326  0.074341  0.017986       0.009592  0.019185   \n",
        "Event             0.008393  0.004796  0.001199       0.004796  0.003597   \n",
        "\n",
        "                 Person     Event  \n",
        "Information    0.065947  0.008393  \n",
        "Glossary       0.070743  0.004796  \n",
        "Question       0.021583  0.005995  \n",
        "Good Practice  0.009592  0.005995  \n",
        "Project        0.017986  0.007194  \n",
        "Person         0.002398  0.011990  \n",
        "Event          0.009592  0.004796  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the table above we can see that for example a document with type 'Information' has a $0.267045$ probability of being linked with another document of type 'Information' and a $0.034091$ probability of being linked with a document of type 'Good Practice'. An overview of the probabilities on a the same dataset for $P(t \\mid d_i \\to d_j)$ and $P(t)$ is computed in the following block."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_t = prob.compute_tag_probs(data, 1)\n",
      "probs_tg = prob.compute_tag_link_prob(data, 1)\n",
      "\n",
      "pandas.set_option('display.max_rows', 7)\n",
      "pandas.DataFrame({\"$P(t)$\": pandas.Series(probs_t.values(), index=probs_t.keys()),\n",
      "                  \"$P(t \\mid d_i \\cdot d_j)$\": pandas.Series(probs_tg.values(), index=probs_tg.keys())})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>$P(t \\mid d_i \\cdot d_j)$</th>\n",
        "      <th>$P(t)$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AcademicSkills</th>\n",
        "      <td> 0.003158</td>\n",
        "      <td> 0.000226</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AcademischeVaardighedenPortfolio</th>\n",
        "      <td> 0.000526</td>\n",
        "      <td> 0.000017</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ActiveLearning</th>\n",
        "      <td> 0.038947</td>\n",
        "      <td> 0.005339</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>iThenticate</th>\n",
        "      <td> 0.000526</td>\n",
        "      <td> 0.000017</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>vraagconstructie</th>\n",
        "      <td> 0.000526</td>\n",
        "      <td> 0.000017</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>webcolleges</th>\n",
        "      <td> 0.014211</td>\n",
        "      <td> 0.001582</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>146 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                                  $P(t \\mid d_i \\cdot d_j)$    $P(t)$\n",
        "AcademicSkills                                     0.003158  0.000226\n",
        "AcademischeVaardighedenPortfolio                   0.000526  0.000017\n",
        "ActiveLearning                                     0.038947  0.005339\n",
        "...                                                     ...       ...\n",
        "iThenticate                                        0.000526  0.000017\n",
        "vraagconstructie                                   0.000526  0.000017\n",
        "webcolleges                                        0.014211  0.001582\n",
        "\n",
        "[146 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This approach still has a problem as it is likely that $T(d_i)\\cap T(d_j) = \\emptyset$. This way we can try to compute $\\max P(d_i \\to d_j\\mid t)$ all we want but we won't find a probability at all. If this happens we can compute $P(d_i \\to d_j \\mid \\emptyset)$ or in other words the probability that two documents are linked given that they have zero tags in agreement. This is computed in the following block.\n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Check the following math please\n",
      "***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Latex\n",
      "\n",
      "links = lambda: ((item, l) for item in data.items() for l in data.item(item)['links']) \n",
      "tags = lambda x: data.item(x)['tags']\n",
      "tag_int = lambda x, y: set(tags(x)).intersection(set(tags(y)))\n",
      "\n",
      "empty, non_empty = [], []\n",
      "for link in links(): (empty, non_empty)[bool(tag_int(*link))].append(link)\n",
      "    \n",
      "avg_tag = np.mean(probs_t.values())\n",
      "zero_tag = len(empty)/float(len(empty)+len(non_empty))\n",
      "    \n",
      "Latex(r\"\"\"The probability of an empty intersection of tag sets is $P(\\emptyset \\mid d_i \\to d_j) = {0}$ \n",
      "          which is ${1}$ times as big as the average $P(t)$ as computed above (mean: ${2}$). This leads us\n",
      "          to the following question. Should we only look at the number of tags in agreement between two documents\n",
      "          to compute the $P(t\\mid d_i \\to d_j)$ and $P(t)$ probability? Next we'll compute the number for this assumptions\n",
      "          and decide if the number we find suit our goal better.\n",
      "        \"\"\".format(zero_tag, int(zero_tag/avg_tag), avg_tag))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "The probability of an empty intersection of tag sets is $P(\\emptyset \\mid d_i \\to d_j) = 0.184713375796$ \n",
        "          which is $77$ times as big as the average $P(t)$ as computed above (mean: $0.00239188858911$). This leads us\n",
        "          to the following question. Should we only look at the number of tags in agreement between two documents\n",
        "          to compute the $P(t\\mid d_i \\to d_j)$ and $P(t)$ probability? Next we'll compute the number for this assumptions\n",
        "          and decide if the number we find suit our goal better.\n",
        "        "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<IPython.core.display.Latex at 0x7ff2c85ba150>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calculate Probability Based on Intersection Cardinality\n",
      "***\n",
      "\n",
      "As we saw before due to the naive bayed assumptions we made it became hard to calculate the joint probabilities. Instead of that we decided to use the maximum probability of the tags of a document. This gave room to a new problem. Namely the problem where the intersections of the tag sets of two documents are the empty set. We tried to solve this by calculating the probabilities for the cases where no tags are in common, but this probability turned out to be too high to use in our system. This would results in way too much link proposols between documents without tags in common. The solution we propose now is to instead of using the tags to use the cardinality of the intersection of the two tag sets. So we compute $P(d_i \\to d_j \\mid |T(d_i) \\cap T(d_j)|)$ or in words the probability that two documents are linked given the number of tags they have in common. Let $\\Sigma_{ij}$ the cardinality of the intersection of the tag sets of document $d_i$ and $d_j$ ($|T(d_i) \\cap T(d_j)|$) then\n",
      "\n",
      "$$ P(d_i \\to d_j \\mid \\Sigma_{ij}) = \\frac{P(\\Sigma_{ij} \\mid d_i \\to d_j)P(d_i \\to d_j)}{P(\\Sigma_{ij})}$$\n",
      "\n",
      "We already know $P(d_i \\to d_j)$ from previous computations. $P(\\Sigma)$ is the probability that two randomly drawn documents $m$ and $n$ have a tag intersection set cardinality of $\\Sigma$:\n",
      "\n",
      "$$ P(\\Sigma) = \\frac{|\\{(m,n) \\mid m,n \\in D \\land \\Sigma_{mn} = \\Sigma \\land m \\neq n \\}|}{2}\\frac{1}{|D| \\choose 2} =\n",
      "\\frac{|\\{(m,n) \\mid m,n \\in D \\land \\Sigma_{mn} = \\Sigma \\land m \\neq n \\}|}{|D| \\cdot (|D| - 1)}$$\n",
      "\n",
      "$P(\\Sigma \\mid d_i \\to d_j)$ is the probability of a tag intersection set cardinality of $\\Sigma$ given that the two documents are linked. We can compute this in the following way:\n",
      "\n",
      "$$ P(\\Sigma \\mid d_i \\to d_j) = \\frac{|\\{(m, n) \\mid m \\to n \\in L \\land \\Sigma_{mn} = \\Sigma \\}|}{|L|} $$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "tags = lambda x: data.item(x)['tags']\n",
      "tag_int = lambda x, y: set(tags(x)).intersection(set(tags(y)))\n",
      "\n",
      "item_card = len(list(data.items()))\n",
      "l_counter = Counter()\n",
      "for item_a in data.items():\n",
      "    for item_b in data.items():\n",
      "        if item_a == item_b: continue\n",
      "        l_counter.update([len(tag_int(item_a, item_b))])\n",
      "        \n",
      "pandas.set_option('display.max_rows', 20)\n",
      "\n",
      "links = lambda: ((item, l) for item in data.items() for l in data.item(item)['links']) \n",
      "link_card = Counter([len(tag_int(*l)) for l in links()])\n",
      "total_link = sum(link_card.values())\n",
      "\n",
      "l_counts = [l_counter[x] + 1 for x in range(0,11)]\n",
      "l_cards = [link_card[x] + 1 for x in range(0,11)]\n",
      "p_sigma = map(lambda x: x/float(item_card*(item_card-1)), l_counts)\n",
      "p_sigma_doc = map(lambda x: x/float(total_link), l_cards)\n",
      "\n",
      "# p_sigma = map(lambda x: x/float(item_card*(item_card-1)), l_counter.values())\n",
      "# p_sigma_doc = map(lambda x: x/float(total_link), link_card.values())\n",
      "\n",
      "p_x = sum(link_card.values())/float(item_card*(item_card-1))\n",
      "\n",
      "pandas.DataFrame({\"$P(\\Sigma)$\": p_sigma,\n",
      "                  \"$P(\\Sigma \\mid d_i \\cdot d_j)$\": p_sigma_doc,\n",
      "                  \"$P(\\Sigma \\mid d_i \\cdot d_j)P(d_i\\cdot d_j)/P(\\Sigma)$\":map(lambda x: (x[0]/x[1]) * p_x, zip(p_sigma_doc, p_sigma))})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>$P(\\Sigma \\mid d_i \\cdot d_j)$</th>\n",
        "      <th>$P(\\Sigma \\mid d_i \\cdot d_j)P(d_i\\cdot d_j)/P(\\Sigma)$</th>\n",
        "      <th>$P(\\Sigma)$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.185987</td>\n",
        "      <td> 0.003110</td>\n",
        "      <td> 0.818323</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.174522</td>\n",
        "      <td> 0.038733</td>\n",
        "      <td> 0.061663</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.249682</td>\n",
        "      <td> 0.038036</td>\n",
        "      <td> 0.089836</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.183439</td>\n",
        "      <td> 0.122553</td>\n",
        "      <td> 0.020485</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.119745</td>\n",
        "      <td> 0.263305</td>\n",
        "      <td> 0.006224</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.050955</td>\n",
        "      <td> 0.330579</td>\n",
        "      <td> 0.002109</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.025478</td>\n",
        "      <td> 0.377358</td>\n",
        "      <td> 0.000924</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.011465</td>\n",
        "      <td> 0.360000</td>\n",
        "      <td> 0.000436</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.005096</td>\n",
        "      <td> 0.800000</td>\n",
        "      <td> 0.000087</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.003822</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.000052</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0.003822</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.000052</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "    $P(\\Sigma \\mid d_i \\cdot d_j)$  \\\n",
        "0                         0.185987   \n",
        "1                         0.174522   \n",
        "2                         0.249682   \n",
        "3                         0.183439   \n",
        "4                         0.119745   \n",
        "5                         0.050955   \n",
        "6                         0.025478   \n",
        "7                         0.011465   \n",
        "8                         0.005096   \n",
        "9                         0.003822   \n",
        "10                        0.003822   \n",
        "\n",
        "    $P(\\Sigma \\mid d_i \\cdot d_j)P(d_i\\cdot d_j)/P(\\Sigma)$  $P(\\Sigma)$  \n",
        "0                                            0.003110           0.818323  \n",
        "1                                            0.038733           0.061663  \n",
        "2                                            0.038036           0.089836  \n",
        "3                                            0.122553           0.020485  \n",
        "4                                            0.263305           0.006224  \n",
        "5                                            0.330579           0.002109  \n",
        "6                                            0.377358           0.000924  \n",
        "7                                            0.360000           0.000436  \n",
        "8                                            0.800000           0.000087  \n",
        "9                                            1.000000           0.000052  \n",
        "10                                           1.000000           0.000052  "
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "link_card"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "Counter({2: 195, 0: 145, 3: 143, 1: 136, 4: 93, 5: 39, 6: 19, 7: 8, 8: 3, 9: 2, 10: 2})"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l_counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "Counter({0: 46938, 2: 5152, 1: 3536, 3: 1174, 4: 356, 5: 120, 6: 52, 7: 24, 8: 4, 9: 2, 10: 2})"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}