\section{Conclusion}
This report has compared six different ways (vectorizers) of converting a text
document into a vector representation and five ways of computing the distance
between these vectors. All this is done in the context of the Starfish network.
Also a method to take the knowledge from the network into account and a way to
determine the number of documents to retrieve were proposed. These combined
form a complete `pipeline' to compute and propose links to known documents for
a new document that is about to be added to the Starfish network.

The following conclusions can be drawn from the present study: firstly, the
text vectorizers perform significantly better for questions, however these do
perform badly on documents of type `person'. On documents of type `person' the
tag vectorizers do perform well. Suprisingly the simple tag vectorizer has the
best performance and is the fastest except for events. For documents of type
`events' it is recommended to use the glossaries of tags vectorizer.  Secondly
the probabilistic model of the network that is proposed is either to simplistic
or the data available is too little. In either case it might be off interest to
further investigate a similar model on a bigger data set. Lastly the method
of selecting the number of documents shows that the precision increases and
performs better than selecting a static number of documents.

The findings in this report are subject to at least three limitations. First,
the proposed solution only works for textual document and not on audio, video
which may be part of the Startfish knowledge graph. Secondly, the data set
that was used during investigation is rather small and may not be representation
of a real life data set. Lastly due to the small training network no cross-validation
was performed which may result in an overfit to the data.

Whilst this study is based on only a small network of documents taken together
these findings do show that the chosen solution is capable of recommending
links between documents with a certainty far above the guessing level. It is
now up to the client to choose if a precision of 45.09\%\todo{Check for correct percentage for different items}
is good enough to let the user select a document to link.

