\documentclass[a4paper]{article}

% Typesetting
%\usepackage{mathpazo}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=20,shrink=20]{microtype}
\microtypecontext{spacing=nonfrench}
\hyphenpenalty=5000
\tolerance=1000
\usepackage{listings}
\usepackage{pdfpages}
\usepackage{tabularx} % in the preamble
\usepackage{setspace}
\addtocontents{toc}{\protect\enlargethispage{\baselineskip}}

% Graphics
\usepackage{graphicx}
\graphicspath{{./images/}}

% Tables
\usepackage{booktabs}

% Utility
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumerate}
\usepackage{eulervm}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{color}
\usepackage{todonotes}

\renewcommand{\algorithmiccomment}[1]{\hfill// \textit{#1}}

\usepackage{framed, color}
\definecolor{shadecolor}{rgb}{0.8, 0.9, 1.0}

% Science Units
\usepackage{textcomp}
\usepackage[]{siunitx}
\sisetup{tophrase=--}
\sisetup{repeatunits=false}
\usepackage{latexsym}

% Bibliography (Use \citep)
\usepackage[]{natbib} %numbers
\setlength{\bibsep}{3.5pt}

\begin{document}

% Title Page
\newgeometry{margin=3cm}
\thispagestyle{empty}
\begin{center}
% StarFish Logo
\includegraphics[width=\linewidth]{logo_starfish_project}\\\vspace{1cm}

% Subtitle
{\large
Finding implicitly related items based on semantic similarities and metadata in a non-hierarchical network of documents
}\\\vspace{0.5cm}

% Authors
\begin{tabular*}{0.8\linewidth}{@{\extracolsep{\fill}}lcr}
& \textbf{Authors} & \\
\hline
R. van Ginkel 	& J. Peters 	& L. Weerts \\
\end{tabular*}
\\\vspace{2cm}
% Company
Project commissioned by \emph{Perceptum B.V.}\\\vspace{1cm}

% Supervisors
\textbf{Supervisors}\\
\begin{tabular}{r|l}
Academic Supervisor & Raquel Fernandez \\
Company Supervisors & Robrecht Jurriaans \\
& Sander Latour \\
& Wijnand Baretta
\end{tabular}


% UvA
\vfill
\today\\
Universiteit van Amsterdam

\end{center}
\restoregeometry

\clearpage

% Front Matter
\begin{abstract}
This report describes the results of the second year's project for the Perceptum team. The project focused on creating a \emph{document link recommender system} to the document knowledge base of the Starfish website, a platform where educators can share information about educational innovation. Because users of Starfish do not have knowledge of all the documents in the entire knowledge base, a system that can perform this automatically is needed. This report describes the implementation and analysis of several algorithms that can perform this task. 

To create the document linker, a document descriptor-based technique was used. Firstly, each of the documents is transformed into a descriptor by algorithms called \emph{vectorizers}. Six vectorizers were implemented. Two vectorizers are based on the text of documents (textvectorizer and weighted text vectorizers) and two others use the tags of documents (simple tag similarity and tag smoothing). The last two vectorizers perform the textual transformation on text-based descriptions of tags (glossaries of tags and weighted tags). Additionally, a hybrid method of a text-based and tag-based is proposed. After creating the document descriptors, a ranking is made of all documents based on the similarity of the document descriptors and the descriptor of the new added document. This was done using the $K$-Nearest Neighbor algorithm with several distance metrics, of which the cosine distance turned out to work the best. The system also provides a method that can re-rank this set of proposed documents based on the probability that two documents are linked together.  The last step in the pipeline determines how many of the nearest neighbours should be returned. For this a threshold was set that compares the distance as calculated with $K$-Nearest Neighbor of two documents with consecutive ranks. 

Three main conclusions were drawn from this study. Firstly, the
text vectorizers performs the best if the newly added document is a Question (42.02-44.82\% accuracy on k-link measuring). However, it cannot deal with
documents that have different languages or non-textual documents such as images, videos
and audio. The simple tag vectorizer has the
best performance (22.80\% overall average accuracy on k-link measuring) and is the fastest. The best overall performance with the k-link measurement
is gained with the hybrid vectorizer (26.13\%) that uses the textvectorizer if no tags are
available and the simple tag vectorizer otherwise. This vectorizer performs as
good on most document types as the simple tag vectorizer, but performs significantly
better on questions (31.93\% versus 16.67\%). Secondly the probabilistic model of the network that is proposed 
is either to simplistic
or the data available is too little. In either case it might be off interest to
further investigate a similar model on a bigger data set. Lastly the method
of selecting the number of documents shows that the overall performance 
does not change significantly if the threshold is added to most vectorizers.
However, the text vectorizers seem to have a bias towards a higher precision in the
trade off between precision and recall. The
glossaries of tags and weighted glossaries of tags get a higher
recall for persons. The best performance while using the threshold was obtained
using the hybrid vectorizer, with an average precision, recall and F1 measure of respectively 28.61\%, 27.26\% and 23.92\%. 

These results are clearly not good enough for an automatic linking system, but could be considered high enough for a recommender system since they are far above guessing level. It is now up to the client to choose if a precision of 28.61\% is good enough to let the user select a document to link and if a recall of 27.26\%
covers enough of the documents within the knowledge base.  
\end{abstract}
\clearpage

\tableofcontents
\clearpage

% Main Matter
% The introduction (dah)
\input{chapters/0_introduction}

% Domain (what are we dealing with and why is it non-trivial
\input{chapters/1_domain}

% Theory (how could this problem theoretically be solved)
\input{chapters/2_theory}

% What have we actually implemented
\input{chapters/3_productoverview}

% Very specific explanation of each of the algorithms in the pipeline and their pro's and cons
\input{chapters/4_method}

% Overview of experiments done on the entire pipeline
\input{chapters/5_experiments}

% Conclusion
\input{chapters/6_conclusion}

% MUCH FUTURE WORK!
\input{chapters/7_future}


% Marshall Matters
\bibliographystyle{apalike}
\bibliography{references.bib}


\end{document}
