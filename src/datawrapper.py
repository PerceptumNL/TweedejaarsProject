
from __future__ import with_statement
import cPickle as pickle
import preprocessing
from copy import deepcopy

class DataWrapper(object):
    """
    This class wraps the data object exported from starfish.
    """

    def __init__(self, data):
        """
        Initialize class and read date file
        """
        if type(data) == str:
            self.datafile = data
            self.read_datafile()
        else:
            self.datefile = None
            self.data = data

    def read_datafile(self):
        """
        Reads the data file and stores in self.data
        """
        with open(self.datafile) as f:
            self.data = pickle.load(f)

    @property
    def tags(self):
        """
        Returns a generator for all tags in the datafile.
        """
        for tag in self.data['tags']:
            yield tag

    def tag(self, tag):
        """
        Returns the dictionary of single tag.
        """
        return self.data['tags'][tag]

    @property
    def items(self):
        """
        A generator for all items in the datefile.
        """
        for item in self.data['items']:
            yield item

    def item(self, item):
        """
        Returns the dictionary of single item.
        """
        return self.data['items'][item]

    def preprocessed_content(self, item):
        """
        Returns the preprocessed text of item if set. Otherwise returns and
        empty string.
        """
        if self.data['items'][item]['type'] == 'Person':
            about = self.preprocessed_by_key(item, 'about')
            headline = self.preprocessed_by_key(item, 'headline')
            return headline + ' ' + about

        title = self.preprocessed_by_key(item, 'title')
        text = self.preprocessed_by_key(item, 'text')
        return title + ' ' + text 

    def preprocessed_contents(self):
        """
        Returns a generator that yields preprocessed texts in all items.
        """
        for item in self.items:
            yield self.preprocessed_content(item)

    def preprocessed_by_key(self, item, key):
        """
        Returns the preprocessed text of item if set. Otherwise returns and
        empty string.
        """
        item = self.data['items'][item]
        if key in item:
            return preprocessing.preprocess_text(item[key])
        else:
            return ''

    def preprocessed_text(self, item):
        """
        Returns the preprocessed text of item if set. Otherwise returns and
        empty string.
        """
        item = self.data['items'][item]
        if 'text' in item:
            return preprocessing.preprocess_text(item['text'])
        else:
            return ''

    def preprocessed_texts(self):
        """
        Returns a generator that yields preprocessed texts in all items.
        """
        for item in self.items:
            yield self.preprocessed_text(item)

    def tag_glossary(self, tag):
        """
        Returns the glossary text of a tag if set. Otherwise returns an
        empty string.
        """
        return self.preprocessed_text(self.tag(tag)['glossary'])
    
    def test_data(self):
        """
        Generate test data sets that consists of a new document not currently
        part of the dataset and a dataset of known documents. These are
        generated by taking and removing a single document from the dataset.
        For this glossaries are ignored as these are part of other structures
        in the dataset.
        """
        for item in self.data['items']:
            data = deepcopy(self.data)
            if self.item(item)['type'] == 'Glossary':
                continue
            del data['items'][item]
            for k,v in data['items'].items():
                try:
                    v['links'].remove(item)
                except ValueError:
                    pass
            yield (self.item(item), DataWrapper(data))
